{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Distance Matrix API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import googlemaps\n",
    "from itertools import tee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desktop/GPS Trajectory/GPS Trajectory/go_track_trackspoints.csv')\n",
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = '***'#enter Google Maps API key\n",
    "gmaps = googlemaps.Client(key=API_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "#empty list - will be used to store calculated distances\n",
    "list = [0]\n",
    "\n",
    "# Loop through each row in the data frame using pairwise\n",
    "for (i1, row1), (i2, row2) in pairwise(df.iterrows()):\n",
    "      #Assign latitude and longitude as origin/departure points\n",
    "      LatOrigin = row1['latitude'] \n",
    "      LongOrigin = row1['longitude']\n",
    "      origins = (LatOrigin,LongOrigin)\n",
    "\n",
    "      #Assign latitude and longitude from the next row as the destination point\n",
    "      LatDest = row2['latitude']   # Save value as lat\n",
    "      LongDest = row2['longitude'] # Save value as lat\n",
    "      destination = (LatDest,LongDest)\n",
    "\n",
    "      #pass origin and destination variables to distance_matrix function# output in meters\n",
    "      result = gmaps.distance_matrix(origins, destination, mode='walking')[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
    "      \n",
    "      #append result to list\n",
    "      list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Distance'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('calculated_distances.csv', sep=';', index=None, header= ['id','Latitude','Longitude','track_id','time','distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocode API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"root\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"***\"\n",
    "# Backoff time sets how many minutes to wait between google pings when your API limit is hit\n",
    "BACKOFF_TIME = 30\n",
    "# Set your output file name here.\n",
    "output_filename = 'Desktop/output-2015.csv'\n",
    "# Set your input file here\n",
    "input_filename = \"Desktop/PPR-2015.csv\"\n",
    "# Specify the column name in your input data that contains addresses here\n",
    "address_column_name = \"Address\"\n",
    "# Return Full Google Results? If True, full JSON results from Google are included in output\n",
    "RETURN_FULL_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data to a Pandas Dataframe\n",
    "data = pd.read_csv('Desktop/PPR-2015.txt', encoding = 'unicode_escape') #.encode('utf-8').strip()\n",
    "\n",
    "if address_column_name not in data.columns:\n",
    "    raise ValueError(\"Missing Address column in input data\")\n",
    "\n",
    "# Form a list of addresses for geocoding:\n",
    "# Make a big list of all of the addresses to be processed.\n",
    "addresses = data[address_column_name].tolist()\n",
    "\n",
    "# **** DEMO DATA / IRELAND SPECIFIC! ****\n",
    "# We know that these addresses are in Ireland, and there's a column for county, so add this for accuracy. \n",
    "# (remove this line / alter for your own dataset)\n",
    "addresses = (data[address_column_name] + ',' + data['County'] + ',Ireland').tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_results(address, api_key=None, return_full_response=False):\n",
    "    \"\"\"\n",
    "    Get geocode results from Google Maps Geocoding API.\n",
    "    \n",
    "    Note, that in the case of multiple google geocode reuslts, this function returns details of the FIRST result.\n",
    "    \n",
    "    @param address: String address as accurate as possible. For Example \"18 Grafton Street, Dublin, Ireland\"\n",
    "    @param api_key: String API key if present from google. \n",
    "                    If supplied, requests will use your allowance from the Google API. If not, you\n",
    "                    will be limited to the free usage of 2500 requests per day.\n",
    "    @param return_full_response: Boolean to indicate if you'd like to return the full response from google. This\n",
    "                    is useful if you'd like additional location details for storage or parsing later.\n",
    "    \"\"\"\n",
    "    # Set up your Geocoding url\n",
    "    geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?address={}\".format(address)\n",
    "    if api_key is not None:\n",
    "        geocode_url = geocode_url + \"&key={}\".format(api_key)\n",
    "        \n",
    "    # Ping google for the reuslts:\n",
    "    results = requests.get(geocode_url)\n",
    "    # Results will be in JSON format - convert to dict using requests functionality\n",
    "    results = results.json()\n",
    "    \n",
    "    # if there's no results or an error, return empty results.\n",
    "    if len(results['results']) == 0:\n",
    "        output = {\n",
    "            \"formatted_address\" : None,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"accuracy\": None,\n",
    "            \"google_place_id\": None,\n",
    "            \"type\": None,\n",
    "            \"postcode\": None\n",
    "        }\n",
    "    else:    \n",
    "        answer = results['results'][0]\n",
    "        output = {\n",
    "            \"formatted_address\" : answer.get('formatted_address'),\n",
    "            \"latitude\": answer.get('geometry').get('location').get('lat'),\n",
    "            \"longitude\": answer.get('geometry').get('location').get('lng'),\n",
    "            \"accuracy\": answer.get('geometry').get('location_type'),\n",
    "            \"google_place_id\": answer.get(\"place_id\"),\n",
    "            \"type\": \",\".join(answer.get('types')),\n",
    "            \"postcode\": \",\".join([x['long_name'] for x in answer.get('address_components') \n",
    "                                  if 'postal_code' in x.get('types')])\n",
    "        }\n",
    "        \n",
    "    # Append some other details:    \n",
    "    output['input_string'] = address\n",
    "    output['number_of_results'] = len(results['results'])\n",
    "    output['status'] = results.get('status')\n",
    "    if return_full_response is True:\n",
    "        output['response'] = results\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Geocoded: 108 THE HARDWICKE VILLAGE, NORTH BRUNSWICK ST, DUBLIN 7,Dublin,Ireland: OK\n",
      "Geocoded: 108 THE HARDWICKE VILLAGE, NORTH BRUNSWICK ST, DUBLIN 7,Dublin,Ireland: OK\n",
      "Geocoded: 12 THE CEDARS, MONKSTOWN VALLEY, MONKSTOWN,Dublin,Ireland: OK\n",
      "Geocoded: 12 THE CEDARS, MONKSTOWN VALLEY, MONKSTOWN,Dublin,Ireland: OK\n",
      "Error geocoding 148 DEEL MANOR, ASKEATON, CO LIMERICK,Limerick,Ireland: REQUEST_DENIED\n",
      "Error geocoding 148 DEEL MANOR, ASKEATON, CO LIMERICK,Limerick,Ireland: REQUEST_DENIED\n",
      "Geocoded: 148 DEEL MANOR, ASKEATON, CO LIMERICK,Limerick,Ireland: REQUEST_DENIED\n",
      "Geocoded: 148 DEEL MANOR, ASKEATON, CO LIMERICK,Limerick,Ireland: REQUEST_DENIED\n",
      "Geocoded: 4 SHREWSBURY, BALLSBRIDGE, DUBLIN 4,Dublin,Ireland: OK\n",
      "Geocoded: 4 SHREWSBURY, BALLSBRIDGE, DUBLIN 4,Dublin,Ireland: OK\n",
      "Geocoded: 41 THE BRIARY, BLAINROE, WICKLOW,Wicklow,Ireland: OK\n",
      "Geocoded: 41 THE BRIARY, BLAINROE, WICKLOW,Wicklow,Ireland: OK\n",
      "Geocoded: 5 ASSUMPTION PLACE, CLONAKILTY, CORK,Cork,Ireland: OK\n",
      "Geocoded: 5 ASSUMPTION PLACE, CLONAKILTY, CORK,Cork,Ireland: OK\n",
      "Geocoded: Coore East, Mullagh, County Clare,Clare,Ireland: OK\n",
      "Geocoded: Coore East, Mullagh, County Clare,Clare,Ireland: OK\n",
      "Geocoded: Kilerrin Road, Moylough, Ballinasloe,Galway,Ireland: OK\n",
      "Geocoded: Kilerrin Road, Moylough, Ballinasloe,Galway,Ireland: OK\n",
      "Finished geocoding all addresses\n",
      "Finished geocoding all addresses\n"
     ]
    }
   ],
   "source": [
    "# Ensure, before we start, that the API key is ok/valid, and internet access is ok\n",
    "test_result = get_google_results(\"London, England\", API_KEY, RETURN_FULL_RESULTS)\n",
    "if (test_result['status'] != 'OK') or (test_result['formatted_address'] != 'London, UK'):\n",
    "    logger.warning(\"There was an error when testing the Google Geocoder.\")\n",
    "    raise ConnectionError('Problem with test results from Google Geocode - check your API key and internet connection.')\n",
    "\n",
    "# Create a list to hold results\n",
    "results = []\n",
    "# Go through each address in turn\n",
    "for address in addresses:\n",
    "    # While the address geocoding is not finished:\n",
    "    geocoded = False\n",
    "    while geocoded is not True:\n",
    "        # Geocode the address with google\n",
    "        try:\n",
    "            geocode_result = get_google_results(address, API_KEY, return_full_response=RETURN_FULL_RESULTS)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Major error with {}\".format(address))\n",
    "            logger.error(\"Skipping!\")\n",
    "            geocoded = True\n",
    "            \n",
    "        # If we're over the API limit, backoff for a while and try again later.\n",
    "        if geocode_result['status'] == 'OVER_QUERY_LIMIT':\n",
    "            logger.info(\"Hit Query Limit! Backing off for a bit.\")\n",
    "            time.sleep(BACKOFF_TIME * 60) # sleep for 30 minutes\n",
    "            geocoded = False\n",
    "        else:\n",
    "            # If we're ok with API use, save the results\n",
    "            # Note that the results might be empty / non-ok - log this\n",
    "            if geocode_result['status'] != 'OK':\n",
    "                logger.warning(\"Error geocoding {}: {}\".format(address, geocode_result['status']))\n",
    "            logger.debug(\"Geocoded: {}: {}\".format(address, geocode_result['status']))\n",
    "            results.append(geocode_result)           \n",
    "            geocoded = True\n",
    "\n",
    "    # Print status every 100 addresses\n",
    "    if len(results) % 100 == 0:\n",
    "        logger.info(\"Completed {} of {} address\".format(len(results), len(addresses)))\n",
    "            \n",
    "    # Every 500 addresses, save progress to file(in case of a failure so you have something!)\n",
    "    if len(results) % 500 == 0:\n",
    "        pd.DataFrame(results).to_csv(\"{}_bak\".format(output_filename))\n",
    "\n",
    "# All done\n",
    "logger.info(\"Finished geocoding all addresses\")\n",
    "# Write the full results to csv using the pandas library.\n",
    "pd.DataFrame(results).to_csv(output_filename, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Street View Static API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import google_streetview for the api module\n",
    "import google_streetview.api\n",
    "\n",
    "# Define parameters for street view api\n",
    "params = [{\n",
    "  'size': '600x300', # max 640x640 pixels\n",
    "  'location': '41.078021,29.0108481',\n",
    "  'heading': '270',\n",
    "  'pitch': '-0.76',\n",
    "  'key': '***'\n",
    "}]\n",
    "\n",
    "# Create a results object\n",
    "results = google_streetview.api.results(params)\n",
    "\n",
    "# Download images to directory 'downloads'\n",
    "results.download_links('downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Languages with Google Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected(lang=hu, confidence=1.0)\n",
      "Detected(lang=sk, confidence=1.0)\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "text1 = '''\n",
    "A Római Birodalom (latinul Imperium Romanum) az ókori Róma által létrehozott \n",
    "államalakulat volt a Földközi-tenger medencéjében\n",
    "'''\n",
    "\n",
    "text2 = '''\n",
    "Vysoké Tatry sú najvyššie pohorie na Slovensku a v Poľsku a sú zároveň jediným \n",
    "horstvom v týchto štátoch s alpským charakterom. \n",
    "'''\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "dt1 = translator.detect(text1)\n",
    "print(dt1)\n",
    "\n",
    "dt2 = translator.detect(text2)\n",
    "print(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borodino savaş\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "translated = translator.translate('Бороди́нское сраже́ние', dest='tr')\n",
    "\n",
    "print(translated.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dobrý deň -> iyi günler\n",
      "majestátny orol -> görkemli kartal\n",
      "krehká dohoda -> kırılgan anlaşması\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "data = ['Dobrý deň', 'majestátny orol', 'krehká dohoda']\n",
    "\n",
    "translated = translator.translate(data, src='sk', dest='tr')\n",
    "\n",
    "for trans in translated:\n",
    "    print(f'{trans.origin} -> {trans.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required module for text  \n",
    "# to speech conversion \n",
    "from gtts import gTTS \n",
    "  \n",
    "# This module is imported so that we can  \n",
    "# play the converted audio \n",
    "import os \n",
    "  \n",
    "# The text that you want to convert to audio \n",
    "mytext = 'Welcome to geeksforgeeks!'\n",
    "  \n",
    "# Language in which you want to convert \n",
    "language = 'en'\n",
    "  \n",
    "# Passing the text and language to the engine,  \n",
    "# here we have marked slow=False. Which tells  \n",
    "# the module that the converted audio should  \n",
    "# have a high speed \n",
    "myobj = gTTS(text=mytext, lang=language, slow=False) \n",
    "  \n",
    "# Saving the converted audio in a mp3 file named \n",
    "# welcome  \n",
    "myobj.save(\"welcome.mp3\") \n",
    "  \n",
    "# Playing the converted file \n",
    "os.system(\"mpg321 welcome.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Detection with Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My First Project-559ff477fc5c.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (and confidence score):\n",
      "===============================================================================\n",
      "Album cover (93.58%)\n",
      "Movie (80.45%)\n",
      "Poster (75.20%)\n",
      "Font (68.57%)\n",
      "Album (63.91%)\n",
      "Photo caption (60.12%)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "image_uri = 'https://www.yeniyeniseyler.com/wp-content/uploads/2018/01/Arif-v-2016-Film-%C5%9Eark%C4%B1lar%C4%B1.jpg'\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = image_uri\n",
    "\n",
    "response = client.label_detection(image=image)\n",
    "\n",
    "print('Labels (and confidence score):')\n",
    "print('=' * 79)\n",
    "for label in response.label_annotations:\n",
    "    print(f'{label.description} ({label.score*100.:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Detection with Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "\"ARIF\n",
      "Fibn Sarkelaru\n",
      "ISKENDER PAYDAS\n",
      "CEM YILMAZ\n",
      "\"\n",
      "bounds: (117,120),(1075,120),(1075,1165),(117,1165)\n",
      "===============================================================================\n",
      "\"ARIF\"\n",
      "bounds: (145,120),(495,127),(493,228),(143,221)\n",
      "===============================================================================\n",
      "\"Fibn\"\n",
      "bounds: (629,236),(789,237),(788,316),(628,315)\n",
      "===============================================================================\n",
      "\"Sarkelaru\"\n",
      "bounds: (803,242),(1074,244),(1073,325),(802,323)\n",
      "===============================================================================\n",
      "\"ISKENDER\"\n",
      "bounds: (117,1121),(390,1121),(390,1155),(117,1155)\n",
      "===============================================================================\n",
      "\"PAYDAS\"\n",
      "bounds: (410,1128),(636,1128),(636,1165),(410,1165)\n",
      "===============================================================================\n",
      "\"CEM\"\n",
      "bounds: (723,1121),(833,1121),(833,1164),(723,1164)\n",
      "===============================================================================\n",
      "\"YILMAZ\"\n",
      "bounds: (854,1128),(1075,1128),(1075,1155),(854,1155)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "image_uri = 'https://www.yeniyeniseyler.com/wp-content/uploads/2018/01/Arif-v-2016-Film-%C5%9Eark%C4%B1lar%C4%B1.jpg'\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = image_uri\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "\n",
    "for text in response.text_annotations:\n",
    "    print('=' * 79)\n",
    "    print(f'\"{text.description}\"')\n",
    "    vertices = [f'({v.x},{v.y})' for v in text.bounding_poly.vertices]\n",
    "    print(f'bounds: {\",\".join(vertices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Recognition with Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "mid: \"/m/02vxmh\"\n",
      "description: \"Bo\\304\\237azi\\303\\247i University\"\n",
      "score: 0.9573410749435425\n",
      "bounding_poly {\n",
      "  vertices {\n",
      "    x: 98\n",
      "    y: 56\n",
      "  }\n",
      "  vertices {\n",
      "    x: 625\n",
      "    y: 56\n",
      "  }\n",
      "  vertices {\n",
      "    x: 625\n",
      "    y: 315\n",
      "  }\n",
      "  vertices {\n",
      "    x: 98\n",
      "    y: 315\n",
      "  }\n",
      "}\n",
      "locations {\n",
      "  lat_lng {\n",
      "    latitude: 41.083767\n",
      "    longitude: 29.051424\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "image_uri = 'https://image.yenisafak.com/resim/imagecrop/2017/08/09/01/59/resized_7b0e6-b18467cdbogaziciuniversitesikayittarihleri.jpg'\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = image_uri\n",
    "\n",
    "response = client.landmark_detection(image=image)\n",
    "\n",
    "for landmark in response.landmark_annotations:\n",
    "    print('=' * 79)\n",
    "    print(landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotional Face Detection with Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "File: face_surprise.jpg\n",
      "Face surprised: LIKELY\n",
      "Face bounds: (105,460),(516,460),(516,938),(105,938)\n",
      "===============================================================================\n",
      "File: face_no_surprise.png\n",
      "Face surprised: VERY_UNLIKELY\n",
      "Face bounds: (126,0),(338,0),(338,202),(126,202)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import vision\n",
    "\n",
    "uri_base = 'gs://cloud-vision-codelab'\n",
    "pics = ['face_surprise.jpg', 'face_no_surprise.png']\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n",
    "\n",
    "for pic in pics:\n",
    "    image.source.image_uri = f'{uri_base}/{pic}'\n",
    "    response = client.face_detection(image=image)\n",
    "\n",
    "    print('=' * 79)\n",
    "    print(f'File: {pic}')\n",
    "    for face in response.face_annotations:\n",
    "        likelihood = vision.enums.Likelihood(face.surprise_likelihood)\n",
    "        vertices = [f'({v.x},{v.y})' for v in face.bounding_poly.vertices]\n",
    "        print(f'Face surprised: {likelihood.name}')\n",
    "        print(f'Face bounds: {\",\".join(vertices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
